{"cells":[{"cell_type":"code","execution_count":133,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T20:49:55.113616Z","iopub.status.busy":"2024-04-12T20:49:55.112979Z","iopub.status.idle":"2024-04-12T20:51:38.645701Z","shell.execute_reply":"2024-04-12T20:51:38.644424Z","shell.execute_reply.started":"2024-04-12T20:49:55.113573Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: chess in /opt/conda/lib/python3.10/site-packages (1.10.0)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.1.4)\n","Requirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.10/site-packages (0.12.2)\n","Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.26.4)\n","Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.11.4)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (3.2.0)\n","Collecting scikeras[tensorflow]\n","  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n","Collecting keras>=3.2.0 (from scikeras[tensorflow])\n","  Downloading keras-3.2.1-py3-none-any.whl.metadata (5.6 kB)\n","Collecting scikit-learn>=1.4.2 (from scikeras[tensorflow])\n","  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Collecting tensorflow>=2.16.1 (from scikeras[tensorflow])\n","  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n","Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->scikeras[tensorflow]) (1.4.0)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->scikeras[tensorflow]) (1.26.4)\n","Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->scikeras[tensorflow]) (13.7.0)\n","Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->scikeras[tensorflow]) (0.0.7)\n","Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->scikeras[tensorflow]) (3.10.0)\n","Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->scikeras[tensorflow]) (0.11.0)\n","Requirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->scikeras[tensorflow]) (0.2.0)\n","Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.4.2->scikeras[tensorflow]) (1.11.4)\n","Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.4.2->scikeras[tensorflow]) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.4.2->scikeras[tensorflow]) (3.2.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (16.0.6)\n","Collecting ml-dtypes (from keras>=3.2.0->scikeras[tensorflow])\n","  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (3.3.0)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (21.3)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (2.31.0)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (69.0.3)\n","Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (4.9.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (1.14.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (1.51.1)\n","Collecting tensorboard<2.17,>=2.16 (from tensorflow>=2.16.1->scikeras[tensorflow])\n","  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (0.35.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=2.16.1->scikeras[tensorflow]) (0.42.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow>=2.16.1->scikeras[tensorflow]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow>=2.16.1->scikeras[tensorflow]) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow>=2.16.1->scikeras[tensorflow]) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow>=2.16.1->scikeras[tensorflow]) (2024.2.2)\n","Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow>=2.16.1->scikeras[tensorflow]) (3.5.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow>=2.16.1->scikeras[tensorflow]) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow>=2.16.1->scikeras[tensorflow]) (3.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow>=2.16.1->scikeras[tensorflow]) (3.1.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.2.0->scikeras[tensorflow]) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.2.0->scikeras[tensorflow]) (2.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras[tensorflow]) (0.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow>=2.16.1->scikeras[tensorflow]) (2.1.3)\n","Downloading keras-3.2.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n","Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, scikit-learn, keras, tensorflow, scikeras\n","  Attempting uninstall: ml-dtypes\n","    Found existing installation: ml-dtypes 0.2.0\n","    Uninstalling ml-dtypes-0.2.0:\n","      Successfully uninstalled ml-dtypes-0.2.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.15.1\n","    Uninstalling tensorboard-2.15.1:\n","      Successfully uninstalled tensorboard-2.15.1\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.1.1\n","    Uninstalling keras-3.1.1:\n","      Successfully uninstalled keras-3.1.1\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.15.0\n","    Uninstalling tensorflow-2.15.0:\n","      Successfully uninstalled tensorflow-2.15.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n","spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","tensorflow-decision-forests 1.8.1 requires tensorflow~=2.15.0, but you have tensorflow 2.16.1 which is incompatible.\n","tensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.16.1 which is incompatible.\n","tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-3.2.1 ml-dtypes-0.3.2 scikeras-0.13.0 scikit-learn-1.4.2 tensorboard-2.16.2 tensorflow-2.16.1\n"]}],"source":["!pip install chess\n","!pip install pandas\n","!pip install imbalanced-learn\n","!pip install scikeras[tensorflow]"]},{"cell_type":"code","execution_count":134,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T20:51:38.648324Z","iopub.status.busy":"2024-04-12T20:51:38.648009Z","iopub.status.idle":"2024-04-12T20:51:40.989390Z","shell.execute_reply":"2024-04-12T20:51:40.988324Z","shell.execute_reply.started":"2024-04-12T20:51:38.648296Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["chmod: changing permissions of '/kaggle/input/classification/download_cl.sh': Read-only file system\n","Files already exist. Skipping download and extraction.\n"]}],"source":["!chmod +x /kaggle/input/classification/download_cl.sh\n","!source /kaggle/input/classification/download_cl.sh"]},{"cell_type":"code","execution_count":135,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T20:51:40.992035Z","iopub.status.busy":"2024-04-12T20:51:40.991265Z","iopub.status.idle":"2024-04-12T20:51:40.997750Z","shell.execute_reply":"2024-04-12T20:51:40.996801Z","shell.execute_reply.started":"2024-04-12T20:51:40.991996Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import seaborn as sns\n","import matplotlib.pyplot as  plt\n","from imblearn.under_sampling import RandomUnderSampler\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":136,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T20:51:41.000373Z","iopub.status.busy":"2024-04-12T20:51:41.000028Z","iopub.status.idle":"2024-04-12T20:51:41.007652Z","shell.execute_reply":"2024-04-12T20:51:41.006933Z","shell.execute_reply.started":"2024-04-12T20:51:41.000346Z"},"trusted":true},"outputs":[],"source":["\n","def condition(x):\n","    # Check if the value in column 64 is equal to 1\n","    return x == 1\n","\n","def filter_data(x,y,color = 1):\n","    # Apply the condition to the entire array\n","    x = x.values\n","    mask = x[:,64] == color\n","    filtered_x = x[mask]\n","    filtered_y = y[mask]\n","    board = filtered_x[:,0:64].reshape((filtered_x.shape[0],8,8))\n","    return board,filtered_y"]},{"cell_type":"code","execution_count":137,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T20:51:41.009527Z","iopub.status.busy":"2024-04-12T20:51:41.008797Z","iopub.status.idle":"2024-04-12T20:51:41.018135Z","shell.execute_reply":"2024-04-12T20:51:41.017243Z","shell.execute_reply.started":"2024-04-12T20:51:41.009495Z"},"trusted":true},"outputs":[],"source":["def load_n_datasets(n,foldername):\n","    all_datasets = []\n","    filenames = os.listdir(foldername)\n","    for i in range(n):\n","        filename = filenames[i]\n","        if filename.endswith('.csv'):\n","            dataset = pd.read_csv(os.path.join('classification_data', filename))\n","            all_datasets.append(dataset)\n","    combined_dataset = pd.concat(all_datasets, ignore_index=True)\n","    \n","    X =  combined_dataset.iloc[:,0:-1]\n","    y =  combined_dataset[\"Evaluation\"].astype(int)\n","    \n","    X,y = filter_data(X,y)\n","    X = X.reshape(X.shape[0], -1)\n","    X = pd.DataFrame(X)\n","    y = pd.DataFrame(y)\n","    \n","    undersampler = RandomUnderSampler()\n","    X_resampled, y_resampled = undersampler.fit_resample(X, y)\n","    return X_resampled,y_resampled"]},{"cell_type":"code","execution_count":138,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T20:51:41.020112Z","iopub.status.busy":"2024-04-12T20:51:41.019444Z","iopub.status.idle":"2024-04-12T20:51:41.028404Z","shell.execute_reply":"2024-04-12T20:51:41.027471Z","shell.execute_reply.started":"2024-04-12T20:51:41.020081Z"},"trusted":true},"outputs":[],"source":["# Initialize empty channels for each piece\n","def bit_map(X):\n","    channels = np.zeros((X.shape[0],8, 8, 12))  # 12 channels for 6 types of pieces for each player\n","\n","    # Generate separate channels for each player\n","    for player in range(2):  # 0 for white pieces, 1 for black pieces\n","        if player ==0:\n","            for piece_type in range(6):  # 6 types of pieces\n","                piece_mask = X == (piece_type + 1)\n","                channels[:, :, :, player * 6 + piece_type] = piece_mask.astype(np.float32)\n","        else:\n","            for piece_type in range(6):  # 6 types of pieces\n","                piece_mask = -1*(X == (-piece_type - 1))\n","                channels[:, :, :, player * 6 + piece_type] = piece_mask.astype(np.float32)\n","    return channels\n"]},{"cell_type":"code","execution_count":139,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T20:51:41.029888Z","iopub.status.busy":"2024-04-12T20:51:41.029553Z","iopub.status.idle":"2024-04-12T20:51:41.040692Z","shell.execute_reply":"2024-04-12T20:51:41.039771Z","shell.execute_reply.started":"2024-04-12T20:51:41.029845Z"},"trusted":true},"outputs":[],"source":["def one_hot_encoding(y):\n","    encoder = OneHotEncoder(sparse_output=False)\n","    one_hot_encoded = encoder.fit_transform(np.array(y).reshape(-1, 1))\n","    return one_hot_encoded\n"]},{"cell_type":"code","execution_count":140,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T20:51:41.042317Z","iopub.status.busy":"2024-04-12T20:51:41.042000Z","iopub.status.idle":"2024-04-12T20:51:55.581929Z","shell.execute_reply":"2024-04-12T20:51:55.580931Z","shell.execute_reply.started":"2024-04-12T20:51:41.042288Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[[ 0  0  0 ...  0  0  0]\n"," [ 0  0 -4 ...  0  0  0]\n"," [ 0  0  6 ...  0  0  0]\n"," ...\n"," [ 0  0  0 ...  0 -6  0]\n"," [ 4  0  0 ...  0  0 -6]\n"," [ 0  0  0 ...  0  0  0]]\n"]}],"source":["X_chess_data,y_chess_data = load_n_datasets(2,'classification_data')\n","\n","X, _, y, _ = train_test_split(X_chess_data, y_chess_data, test_size=0.01, random_state=42, stratify=y_chess_data)\n","\n","X = np.array(X)\n","y = np.array(y)\n","X = X.reshape((X.shape[0],8,8))"]},{"cell_type":"code","execution_count":141,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T20:51:55.583746Z","iopub.status.busy":"2024-04-12T20:51:55.583393Z","iopub.status.idle":"2024-04-12T20:51:59.305356Z","shell.execute_reply":"2024-04-12T20:51:59.304299Z","shell.execute_reply.started":"2024-04-12T20:51:55.583719Z"},"trusted":true},"outputs":[],"source":["y = one_hot_encoding(y)\n","X = bit_map(X)\n","\n","num_classes = len(np.unique(np.argmax(y,axis=1),axis=0))\n"]},{"cell_type":"code","execution_count":143,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T20:51:59.322260Z","iopub.status.busy":"2024-04-12T20:51:59.321944Z","iopub.status.idle":"2024-04-12T20:52:05.029983Z","shell.execute_reply":"2024-04-12T20:52:05.028908Z","shell.execute_reply.started":"2024-04-12T20:51:59.322233Z"},"trusted":true},"outputs":[],"source":["X_train,X_val,y_train,y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","X_val,X_test,y_val,y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=42, stratify=y_val)"]},{"cell_type":"code","execution_count":144,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T20:52:05.031507Z","iopub.status.busy":"2024-04-12T20:52:05.031210Z","iopub.status.idle":"2024-04-12T20:52:05.056346Z","shell.execute_reply":"2024-04-12T20:52:05.055390Z","shell.execute_reply.started":"2024-04-12T20:52:05.031477Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras import models\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","from sklearn.model_selection import train_test_split\n","\n","tf.random.set_seed(101)\n"]},{"cell_type":"code","execution_count":145,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T20:52:05.060534Z","iopub.status.busy":"2024-04-12T20:52:05.060240Z","iopub.status.idle":"2024-04-12T20:52:05.071790Z","shell.execute_reply":"2024-04-12T20:52:05.070977Z","shell.execute_reply.started":"2024-04-12T20:52:05.060498Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n","from tensorflow.keras.activations import elu\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.optimizers import Adam\n","\n","def create_model(n_neurons=500,n_layers=1,activation=\"elu\",dropout=0.3,l2=0.01):\n","    model = Sequential()\n","    model.add(Conv2D(20, kernel_size=(5, 5), activation=elu, input_shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])))\n","    model.add(Conv2D(50, kernel_size=(3, 3), activation=elu))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Flatten())\n","    for i in range(n_layers):\n","        model.add(Dense(n_neurons, activation=activation,kernel_regularizer=regularizers.l2(l2)))\n","    model.add(Dropout(dropout))\n","    model.add(BatchNormalization())\n","    model.add(Dense(num_classes, activation='softmax'))\n","    model.compile(optimizer=Adam(learning_rate=0.01), loss=\"categorical_crossentropy\")\n","    #model.summary()\n","    return model"]},{"cell_type":"code","execution_count":146,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T20:52:05.073137Z","iopub.status.busy":"2024-04-12T20:52:05.072842Z","iopub.status.idle":"2024-04-12T20:52:05.086614Z","shell.execute_reply":"2024-04-12T20:52:05.085735Z","shell.execute_reply.started":"2024-04-12T20:52:05.073115Z"},"trusted":true},"outputs":[],"source":["def run_model(X_train,y_train,X_val,y_val,X_test,y_test,activation,n_layers,n_neurons,dropout,batch_size,l2,epochs):\n","\n","    model = create_model(activation=activation,n_layers=n_layers,n_neurons=n_neurons,dropout=dropout,l2=l2)\n","    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n","\n","    # Evaluate the model on the test set\n","    predictions = model.predict(X_test)\n","    mae = mean_absolute_error(y_test, predictions)\n","    rmse = mean_squared_error(y_test, predictions, squared=False)\n","\n","    print(\"Test Mean Absolute Error:\", mae)\n","    print(\"Test Root Mean Squared Error:\", rmse)\n","    return history,model"]},{"cell_type":"code","execution_count":149,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T20:52:24.571084Z","iopub.status.busy":"2024-04-12T20:52:24.570188Z","iopub.status.idle":"2024-04-12T20:52:24.579761Z","shell.execute_reply":"2024-04-12T20:52:24.578692Z","shell.execute_reply.started":"2024-04-12T20:52:24.571051Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import RandomizedSearchCV,StratifiedKFold\n","from scikeras.wrappers import KerasClassifier\n","\n","def run_random_search_cv(X_data,y_data):\n","    param_dist = {\n","        'n_neurons': [100,250,500],\n","        'n_layers': [1,2],\n","        'activation':  ['elu','relu','leaky_relu'],\n","        'dropout':[0,0.3,0.6],\n","        'l2': [0,0.01,0.05, 0.1],\n","    }\n","\n","    keras_model = KerasClassifier(model=create_model, \n","                                  n_neurons = param_dist['n_neurons'],\n","                                  n_layers = param_dist['n_layers'],\n","                                  activation = param_dist['activation'],\n","                                  dropout = param_dist['dropout'],\n","                                  l2 = param_dist['l2'],\n","                                  verbose=0)\n","    print(keras_model.get_params().keys())\n","    random_search = RandomizedSearchCV(estimator=keras_model, \n","                                    param_distributions=param_dist, \n","                                    n_iter=100, \n","                                    scoring = \"accuracy\",\n","                                    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n","                                    verbose=0)\n","\n","    random_search.fit(X_data, y_data)\n","\n","    print(random_search.best_params_)\n","    print(random_search.best_score_)\n","    print(random_search.cv_results_)\n","\n"]},{"cell_type":"code","execution_count":150,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T20:52:24.583646Z","iopub.status.busy":"2024-04-12T20:52:24.583247Z","iopub.status.idle":"2024-04-12T20:52:24.594654Z","shell.execute_reply":"2024-04-12T20:52:24.593785Z","shell.execute_reply.started":"2024-04-12T20:52:24.583614Z"},"trusted":true},"outputs":[],"source":["\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n","from tensorflow.keras.activations import elu\n","from tensorflow.keras import regularizers\n","\n","def create_model2(hp):\n","    n_neurons = hp.Int('n_neurons', min_value=250, max_value=750, step=250)\n","    n_layers = hp.Int('n_layers', min_value=1, max_value=2, step=1)\n","    dropout = hp.Choice('dropout', values=[0.0,0.3,0.6])\n","    activation = hp.Choice('activation', values=['elu', 'leaky_relu'])\n","    l2 = hp.Choice('l2', values=[0.0,0.01, 0.1])\n","    model = Sequential()\n","    model.add(Conv2D(20, kernel_size=(5, 5), activation=elu, input_shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])))\n","    model.add(Conv2D(50, kernel_size=(3, 3), activation=elu))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Flatten())\n","    for i in range(n_layers):\n","        model.add(Dense(n_neurons, activation=activation,kernel_regularizer=regularizers.l2(l2)))\n","    model.add(Dropout(dropout))\n","    model.add(BatchNormalization())\n","    model.add(Dense(num_classes, activation='softmax'))\n","    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",metrics=['accuracy'])\n","    #model.summary()\n","    return model\n"]},{"cell_type":"code","execution_count":151,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T20:52:24.596285Z","iopub.status.busy":"2024-04-12T20:52:24.595970Z","iopub.status.idle":"2024-04-12T20:52:24.608766Z","shell.execute_reply":"2024-04-12T20:52:24.607917Z","shell.execute_reply.started":"2024-04-12T20:52:24.596253Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from kerastuner.tuners import RandomSearch\n","from kerastuner.engine.hyperparameters import HyperParameters\n","\n","def custom_evaluation(model, X_val, y_val):\n","    # Evaluate the model on the validation set\n","    loss, accuracy = model.evaluate(X_val, y_val)\n","    return accuracy\n","\n","def run_random_search2(X_train,y_train,X_val, y_val):\n","    tuner = RandomSearch(\n","        create_model2,\n","        objective='val_accuracy',\n","        max_trials=60,  # Number of hyperparameter combinations to try\n","        executions_per_trial=1,  # Number of models to build and train for each trial\n","        directory='test2',  # Directory to save the results\n","        project_name='test')  # Name for the project\n","\n","\n","    # Start the hyperparameter search\n","    tuner.search(X_train, y_train, epochs=20, validation_data=(X_val, y_val), batch_size=128)\n","\n","    # Get the best hyperparameters\n","    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n","\n","    print(\"The best hyperparameters are:\")\n","    for hparam in best_hps.space:\n","        name = hparam.name\n","        value = best_hps.get(name)\n","        print(f\"{name}: {value}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T20:52:24.610617Z","iopub.status.busy":"2024-04-12T20:52:24.610345Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Trial 5 Complete [00h 01m 36s]\n","val_accuracy: 0.3271607458591461\n","\n","Best val_accuracy So Far: 0.3415864109992981\n","Total elapsed time: 00h 47m 24s\n","\n","Search: Running Trial #6\n","\n","Value             |Best Value So Far |Hyperparameter\n","500               |250               |n_neurons\n","1                 |1                 |n_layers\n","0                 |0.3               |dropout\n","elu               |elu               |activation\n","0.01              |0                 |l2\n","256               |128               |batchsize\n","\n","Epoch 1/20\n","\u001b[1m1891/1891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.2133 - loss: 2.5220 - val_accuracy: 0.1991 - val_loss: 2.3205\n","Epoch 2/20\n","\u001b[1m1891/1891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2611 - loss: 2.0688 - val_accuracy: 0.2623 - val_loss: 2.0500\n","Epoch 3/20\n","\u001b[1m1891/1891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2725 - loss: 2.0249 - val_accuracy: 0.2567 - val_loss: 2.0520\n","Epoch 4/20\n","\u001b[1m1891/1891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.2794 - loss: 1.9948 - val_accuracy: 0.2785 - val_loss: 1.9936\n","Epoch 5/20\n","\u001b[1m1885/1891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2852 - loss: 1.9718"]}],"source":["grid_search = True\n","X_data = X\n","y_data = np.argmax(y,axis=1)\n","X_val_data = X_val\n","y_val_data = np.argmax(y_val,axis=1)\n","num_splits = 5\n","if not grid_search:\n","    activation = 'elu'\n","    n_layers = 1\n","    n_neurons = 500\n","    dropout = 0.3\n","    batch_size = 128\n","    l2 = 0.01\n","    epochs = 30\n","    train_histories = []\n","    val_histories = []\n","    models = []\n","    accuracies = []\n","    skf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n","    for train_index, val_index in skf.split(X_data, y_data):\n","        X_train, X_val = X[train_index], X[val_index]\n","        y_train, y_val = y[train_index], y[val_index]\n","        history,model = run_model(X_train,y_train,X_val,y_val,X_test,y_test,activation,n_layers,n_neurons,dropout,batch_size,l2,epochs)\n","        train_histories.append(history.history['loss'])\n","        val_histories.append(history.history['val_loss'])\n","        models.append(model)\n","        y_pred = model.predict(X_test)\n","        y_pred = np.argmax(y_pred, axis = 1)\n","        accuracy = np.sum((y_pred==np.argmax(y_test,axis=1))==True)/len(y_pred)\n","        accuracies.append(accuracy)\n","        break\n","else:\n","    #run_random_search_cv(X_data,y_data)\n","    print(y_val_data.shape)\n","    print(y_data.shape)\n","    run_random_search2(X,y,X_val, y_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["if not grid_search:\n","    print(\"Max accuracy:\",np.max(accuracies))\n","    plt.plot(np.mean(train_histories, axis=0), label='Training Loss')\n","    plt.plot(np.mean(val_histories, axis=0), label='Validation Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.title('Training and Validation Loss over Epochs')\n","    plt.legend()\n","    plt.show()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4778227,"sourceId":8093102,"sourceType":"datasetVersion"}],"dockerImageVersionId":30683,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
